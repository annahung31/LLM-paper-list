# Oral

prompting
[Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://neurips.cc/virtual/2023/oral/73874)
[Why think step by step? Reasoning emerges from the locality of experience](https://neurips.cc/virtual/2023/oral/73821)

efficient training
[Fine-Tuning Language Models with Just Forward Passes](https://neurips.cc/virtual/2023/oral/73844)
[QLoRA: Efficient Finetuning of Quantized LLMs](https://neurips.cc/virtual/2023/oral/73855)
[Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture](https://neurips.cc/virtual/2023/oral/73841)

### rlhf
[Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://neurips.cc/virtual/2023/oral/73865)
[Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained Models](https://neurips.cc/virtual/2023/oral/73879)
[Bridging RL Theory and Practice with the Effective Horizon](https://neurips.cc/virtual/2023/oral/73859)
[Are Emergent Abilities of Large Language Models a Mirage?](https://neurips.cc/virtual/2023/oral/73863)
[Siamese Masked Autoencoders](https://neurips.cc/virtual/2023/oral/73813)

### data?
[DataComp: In search of the next generation of multimodal datasets](https://neurips.cc/virtual/2023/oral/73739)

[Scaling Data-Constrained Language Models](https://neurips.cc/virtual/2023/oral/73832)
[OpenAssistant Conversations - Democratizing Large Language Model Alignment](https://neurips.cc/virtual/2023/oral/73741)

RAG
[LeanDojo: Theorem Proving with Retrieval-Augmented Language Models](https://neurips.cc/virtual/2023/oral/73738)

knowledge graph
[How to Turn Your Knowledge Graph Embeddings into Generative Models](https://neurips.cc/virtual/2023/oral/73848)

### combinatorial problem
[Optimizing Solution-Samplers for Combinatorial Problems: The Landscape of Policy-Gradient Method](https://neurips.cc/virtual/2023/oral/73826)

[Bridging Discrete and Backpropagation: Straight-Through and Beyond](https://neurips.cc/virtual/2023/oral/73827)

### multi modal 
# LLaVA:¬†Large¬†Language¬†and¬†Vision¬†Assistant

### Visual Instruction Tuning
[LLaVA (llava-vl.github.io)](https://llava-vl.github.io/)

Tool use
[Toolformer: Language Models Can Teach Themselves to Use Tools](https://neurips.cc/virtual/2023/oral/73843)
[ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings](https://neurips.cc/virtual/2023/oral/73868)


CV
[Understanding Diffusion Objectives as the ELBO with Simple Data Augmentation](https://neurips.cc/virtual/2023/oral/73857)



## spotlight
[MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning](https://neurips.cc/virtual/2023/poster/73497)


equivariant 
¬†[Clifford Group Equivariant Neural Networks](https://neurips.cc/virtual/2023/poster/70525)
¬†3D view point 
¬†## $SE(3)$ Equivariant Convolution and Transformer in Ray Space [70778.png (4844√ó2710) (neurips.cc)](https://neurips.cc/media/PosterPDFs/NeurIPS%202023/70778.png?t=1701834127.32113)
¬†
privacy / distillation
[Students Parrot Their Teachers: Membership Inference on Model Distillation](https://neurips.cc/virtual/2023/poster/71209)


LLM-rlhf
alpaca farm [neurips.cc/media/neurips-2023/Slides/72842_eQCLdQJ.pdf](https://neurips.cc/media/neurips-2023/Slides/72842_eQCLdQJ.pdf)

Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision

optimizers
Memory Efficient Optimizers with 4-bit States [Memory Efficient Optimizers with 4-bit States Poster (nips.cc)](https://nips.cc/virtual/2023/poster/70507)
Convergence of Adam Under Relaxed Assumptions [Convergence of Adam Under Relaxed Assumptions Poster (neurips.cc)](https://neurips.cc/virtual/2023/poster/69959)
LLM
Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers [Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers Poster (neurips.cc)](https://neurips.cc/virtual/2023/poster/70129)

LLM quantization
QuIP: 2-Bit Quantization of Large Language Models With Guarantees [QuIP: 2-Bit Quantization of Large Language Models With Guarantees Poster (neurips.cc)](https://neurips.cc/virtual/2023/poster/69982)


Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient Pre-LN Transformers [Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient Pre-LN Transformers Poster (neurips.cc)](https://neurips.cc/virtual/2023/poster/69918)

prompting
Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective [NeurIPS 2023 Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective Oral](https://neurips.cc/virtual/2023/oral/73822)
Optimizing Prompts for Text-to-Image Generation [Optimizing Prompts for Text-to-Image Generation Poster (neurips.cc)](https://neurips.cc/virtual/2023/poster/72460)

Graph
Structure-free Graph Condensation: From Large-scale Graphs to Condensed Graph-free Data [Structure-free Graph Condensation: From Large-scale Graphs to Condensed Graph-free Data Poster (neurips.cc)](https://neurips.cc/virtual/2023/poster/71338)

CV- diffusion model 
Parallel Sampling of Diffusion Models [Parallel Sampling of Diffusion Models Poster (neurips.cc)](https://neurips.cc/virtual/2023/poster/71125)
Stable Diffusion is Unstable  [Stable Diffusion is Unstable Poster (neurips.cc)](https://neurips.cc/virtual/2023/poster/70194)
data mixture 

DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining [DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining Poster (neurips.cc)](https://neurips.cc/virtual/2023/poster/70588i)


# Unsorted
- SimMTM: A Simple Pre-Training Framework for Masked Time-Series Modeling Poster
- Learning List-Level Domain-Invariant Representations for Ranking Poster
- Model Spider: Learning to Rank Pre-Trained Models Efficiently Poster
- Scaling Open-Vocabulary Object Detection Poster
- Unified Embedding: Battle-Tested Feature Representations for Web-Scale ML Systems Poster
- One Fits All: Power General Time Series Analysis by Pretrained LM Poster
- Text-to-Image Diffusion Models are Zero Shot Classifiers Poster
- The Geometry of Neural Nets' Parameter Spaces Under Reparametrization Poster
- The Pursuit of Human Labeling: A New Perspective on Unsupervised Learning Poster
- Uncertainty Quantification over Graph with Conformalized Graph Neural Networks Poster
- Trans-Dimensional Generative Modeling via Jump Diffusion Models Poster
- Let the Flows Tell: Solving Graph Combinatorial Problems with GFlowNets Poster
- Can Language Models Solve Graph Problems in Natural Language? Poster
- Regularized Behavior Cloning for Blocking the Leakage of Past Action Information Poster
- 4M: Massively Multimodal Masked Modeling Poster
- 3D-LLM: Injecting the 3D World into Large Language Models Poster
- Double Gumbel Q-Learning Poster
- Separable Physics-Informed Neural Networks Poster
- Multi Time Scale World Models Poster
- Parselüêç: Algorithmic Reasoning with Language Models by Composing Decompositions Poster
- DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data Poster
- Score-based Generative Models with L√©vy Processes Poster
- EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought Poster
- Skill-it! A data-driven skills framework for understanding and training language models Poster
- Outlier-Robust Gromov-Wasserstein for Graph Data Poster
- Bootstrapping Vision-Language Learning with Decoupled Language Pre-training Poster
- SE(3) Equivariant Augmented Coupling Flows Poster
- Stable Nonconvex-Nonconcave Training via Linear Interpolation Poster
- Supervised Pretraining Can Learn In-Context Reinforcement Learning Poster
- Alternating Updates for Efficient Transformers Poster
- PRODIGY: Enabling In-context Learning Over Graphs Poster
- Faith and Fate: Limits of Transformers on Compositionality Poster
- Train Once, Get a Family: State-Adaptive Balances for Offline-to-Online Reinforcement Learning Poster
- On the Planning Abilities of Large Language Models - A Critical Investigation Poster
- Demystifying Oversmoothing in Attention-Based Graph Neural Networks Poster
- Stochastic Multi-armed Bandits: Optimal Trade-off among Optimality, Consistency, and Tail Risk Poster
- ProPILE: Probing Privacy Leakage in Large Language Models Poster
- Hierarchical Decomposition of Prompt-Based Continual Learning: Rethinking Obscured Sub-optimality Poster
- Data Contribution Estimation for Machine Learning Tutorial

